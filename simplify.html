<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>constraining complexity of mixed models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="simplify_files/libs/clipboard/clipboard.min.js"></script>
<script src="simplify_files/libs/quarto-html/quarto.js"></script>
<script src="simplify_files/libs/quarto-html/popper.min.js"></script>
<script src="simplify_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="simplify_files/libs/quarto-html/anchor.min.js"></script>
<link href="simplify_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="simplify_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="simplify_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="simplify_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="simplify_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">constraining complexity of mixed models</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>An R-centric discussion of what to do to manage the complexity of mixed models, specifically their random effect components.</p>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">setup</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For this example we’ll think about a forest restoration experiment with four plots; 5 restoration treatments that are applied in each plot (a randomized complete block design); and 6 replicates within each block/treatment.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">plot =</span> <span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ttt =</span> <span class="fu">factor</span>(LETTERS[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]),</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">rep =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="do">## sample a random 5x5 correlation matrix</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>cchol <span class="ot">&lt;-</span> nimble<span class="sc">::</span><span class="fu">rlkj_corr_cholesky</span>(<span class="at">n =</span> <span class="dv">1</span>, <span class="at">eta =</span> <span class="fl">1.2</span>, <span class="at">p =</span> <span class="dv">5</span>) <span class="sc">*</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="do">## scale by random SDs</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rlnorm</span>(<span class="dv">5</span>, <span class="at">meanlog =</span> <span class="dv">0</span>, <span class="at">sdlog =</span> <span class="fl">0.2</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">t</span>(cchol)[<span class="fu">lower.tri</span>(cchol, <span class="at">diag =</span> <span class="cn">TRUE</span>)]</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>dd<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">suppressMessages</span>(</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">simulate</span>( <span class="sc">~</span> ttt <span class="sc">+</span> (ttt<span class="sc">|</span>plot),</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">family =</span> gaussian,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>             <span class="at">newdata =</span> dd,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>             <span class="at">newparams =</span> <span class="fu">list</span>(<span class="at">beta =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="at">by =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">length.out =</span> <span class="dv">5</span>),</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>                              <span class="at">theta =</span> theta,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>                              <span class="at">sigma =</span> <span class="dv">1</span>)))[[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="maximal-model" class="level2">
<h2 class="anchored" data-anchor-id="maximal-model">maximal model</h2>
<p>We would like to be able to fit <code>~ ttt + (ttt|plot)</code>, but that’s very unlikely to actually work:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lmer</span>(y <span class="sc">~</span> ttt <span class="sc">+</span> (ttt<span class="sc">|</span>plot), <span class="at">data  =</span> dd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>boundary (singular) fit: see help('isSingular')</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">isSingular</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getME</span>(m1, <span class="st">"theta"</span>)[<span class="fu">getME</span>(m1, <span class="st">"lower"</span>) <span class="sc">==</span><span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>plot.(Intercept)        plot.tttB        plot.tttC        plot.tttD 
       0.9465067        1.6882164        0.6333647        0.0000000 
       plot.tttE 
       0.0000000 </code></pre>
</div>
</div>
<p>Seems pretty clear here that the real rank of the estimate is 3 …</p>
</section>
<section id="diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="diagnostics">diagnostics</h2>
<p>Investigate eigenvectors of the estimated <span class="math inline">\(\Sigma\)</span>; we can see again that the covariance matrix has 2 trivial (<span class="math inline">\(\approx 0\)</span>) eigenvalues, but not much else; the rotation matrix doesn’t give us any particularly useful clues about how to simplify the model (maybe a heatmap with column (eigenvector) order held fixed and reordering and hierarchical clustering done on the rows would be helpful for identifying clusters? Ideally, the clustering would be done based on shared similarity based on <em>absolute values</em> (i.e., we might want to identify linear combinations/contrasts among terms that would allow us to simplify the model … surely someone has done something like this?) [<code>rePCA()</code> definitely could use some additions to make it more useful, e.g.&nbsp;a plot method … even the original paper <span class="citation" data-cites="bates_parsimonious_2015">(<a href="#ref-bates_parsimonious_2015" role="doc-biblioref">Bates, Kliegl, et al. 2015</a>)</span> doesn’t offer much guidance …]</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>(r <span class="ot">&lt;-</span> <span class="fu">rePCA</span>(m1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$plot
Standard deviations (1, .., p=5):
[1] 2.124898e+00 1.259986e+00 1.015020e+00 1.794922e-08 0.000000e+00

Rotation (n x k) = (5 x 5):
           [,1]        [,2]       [,3]       [,4]          [,5]
[1,] -0.2084363 -0.35887528  0.6933225 -0.2152625  5.483875e-01
[2,]  0.8630464  0.30871339  0.2515409  0.1513137  2.714376e-01
[3,]  0.1172202 -0.58554419  0.1806518  0.7293481 -2.807378e-01
[4,]  0.1177251  0.06948193  0.5379321 -0.3810027 -7.394451e-01
[5,]  0.4290752 -0.65438127 -0.3660944 -0.5036412 -1.942890e-16

attr(,"class")
[1] "prcomplist"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">Matrix</span>(r<span class="sc">$</span>plot<span class="sc">$</span>rotation))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="simplify_files/figure-html/repca-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="model-constraint-strategies" class="level2">
<h2 class="anchored" data-anchor-id="model-constraint-strategies">model constraint strategies</h2>
<p>When we constrain the covariance matrix (i.e.&nbsp;any model for specific than “general positive semi-definite”), the model results and definition depend on the contrasts used. For factor terms, it might make the most sense to specify sum-to-zero contrasts unless there is a clear reference/control level against which all other levels should be compared; for continuous terms, the predictors should probably be zero centered (or at least zeroed at some sensible reference level; see the end of section 2.2 in <span class="citation" data-cites="bates_fitting_2015">Bates, Mächler, et al. (<a href="#ref-bates_fitting_2015" role="doc-biblioref">2015</a>)</span>).</p>
<section id="compound-symmetric-models" class="level3">
<h3 class="anchored" data-anchor-id="compound-symmetric-models">compound-symmetric models</h3>
<p>For factor models with many levels, compound-symmetric models are a good simplification approach. This restricts the correlations among levels to be identical for all pairs of levels (i.e., a correlation matrix with all off-diagonal elements equal to the same constant <span class="math inline">\(\rho\)</span>).</p>
<p>For example, working with the built-in <code>cbpp</code> data set where <code>period</code> is a four-level factor, the covariance matrices implied by <code>(period|herd)</code> vs.&nbsp;<code>(1|period/herd)</code> are:</p>
<p><span class="math display">\[
(\textrm{intercept}, \textrm{slope}) =
\textrm{MVN}\left(\boldsymbol 0,
\left[
\begin{array}{cccc}
\sigma^2_{\{h|1\}}  &amp; . &amp; . &amp; .  \\
\sigma_{\{h|1\},\{h|p_{21}\}} &amp;
\sigma^2_{\{h|p_{21}\}} &amp; . &amp; .  \\
\sigma_{\{h|1\},     \{h|p_{31}\}} &amp;
\sigma_{\{h|p_{21}\},\{h|p_{31}\}} &amp;
\sigma^2_{\{h|p_{31}\}} &amp; .  \\
\sigma_{\{h|1\}     ,\{h|p_{41}\}} &amp;
\sigma_{\{h|p_{21}\},\{h|p_{41}\}} &amp;
\sigma_{\{h|p_{31}\},\{h|p_{41}\}} &amp;
\sigma^2_{\{h|p_{41}\}}
\end{array}
\right]
\right)
\]</span> (=<span class="math inline">\((n(n+1))/2 = (4\times 5)/2 = 10\)</span> parameters) vs. <span class="math display">\[
\left[
\begin{array}{cccc}
\sigma^2 &amp; . &amp; . &amp; .  \\
\rho \sigma^2 &amp; \sigma^2 &amp; . &amp; .  \\
\rho \sigma^2 &amp; \rho \sigma^2 &amp; \sigma^2 &amp; .   \\
\rho \sigma^2 &amp; \rho \sigma^2 &amp; \rho \sigma^2 &amp; \sigma^2  \\
\end{array}
\right]
\]</span> where <span class="math inline">\(\sigma^2 = \sigma^2_{\{b|1\}}+\sigma^2_{\{herd:period|1\}}\)</span>, <span class="math inline">\(\rho = \sigma^2_{\{b|1\}}/\sigma^2\)</span> (=2 parameters; <span class="math inline">\(\rho\)</span> must be &gt;0)</p>
<ul>
<li>The shortcut of using a nested model works in most mixed model frameworks (almost any platform that allows for multiple random effects will allow them to be nested), but is restricted to positive compound-symmetric models (i.e.&nbsp;<span class="math inline">\(\rho&gt;0\)</span>). Some packages allow general compound symmetric matrices (i.e.&nbsp;<span class="math inline">\(-1 &lt; \rho &lt; 1\)</span>), e.g.&nbsp;using <code>pdCompSymm</code> in <code>nlme</code>, <code>cs()</code> in <code>glmmTMB</code>, <code>cosy</code> in <code>brms</code> (apparently <code>MCMCglmm</code> doesn’t have a CS struture?) …</li>
<li>We also need to distinguish between <em>heterogeneous</em> compound symmetry (i.e., variances are the same for every level; <span class="math inline">\(n+1\)</span> parameters for an <span class="math inline">\(n \times n\)</span> covariance matrix) and <em>homogeneous</em> compound symmetry (all variances are the same, 2 parameters regardless of the size of the cov matrix). The nesting trick described above only handles homogeneous CS. <code>cs()</code> in <code>glmmTMB</code> does heterogeneous CS, homogeneous CS could be handled by using the <code>map</code> argument to fix all of the standard deviations to be the same (or a <code>homcs()</code> structure could be added if there’s enough demand for it).</li>
</ul>
</section>
<section id="independence-models" class="level3">
<h3 class="anchored" data-anchor-id="independence-models">independence models</h3>
<p>This is probably the best known approach to model simplification (e.g.&nbsp;as recommended by <span class="citation" data-cites="barr_random_2013">Barr et al. (<a href="#ref-barr_random_2013" role="doc-biblioref">2013</a>)</span>). It’s actually a special case of CS, with <span class="math inline">\(\rho=0\)</span>. Also called “diagonal” for obvious (?) reasons.</p>
<ul>
<li>in <code>lme4</code> (or <code>glmmTMB</code> or <code>brms</code>), use <code>||</code> in place of <code>|</code>; <code>glmmTMB</code> allows <code>diag()</code> for heterogenous diagonal/independence models (and <code>homdiag()</code> for homogeneous); <code>MCMCglmm</code> uses <code>idv()</code> (homogeneous) and <code>idh()</code> (heterogeneous).</li>
<li><code>||</code> (still) doesn’t work in <code>lme4</code> for factor-valued terms; use <code>afex::mixed</code> or <code>glmmTMB</code>, or expand the model in dummies (<code>(0 + dummy(f, level1)|g) + (0 + dummy(f, level2)|g) + ...</code>; kind of a pain for large numbers of factors, although you could construct it via string processing if you wanted)</li>
<li>see general comments above about the dependence of the constrained model on the zero point of the numeric terms</li>
</ul>
</section>
<section id="dropping-terms" class="level3">
<h3 class="anchored" data-anchor-id="dropping-terms">dropping terms</h3>
<p>Especially for vector-valued random effects consisting of variation in multiple numeric predictors, it may make sense to drop the random effect term for terms with very small variance, or terms that are of less interest. For example, you might reduce the random-effect term <code>(1 + fire + NPP | biome)</code> to <code>(1 + fire | biome)</code> by dropping the variation in <code>NPP</code> across biomes.</p>
</section>
<section id="reduced-rank-models" class="level3">
<h3 class="anchored" data-anchor-id="reduced-rank-models">reduced-rank models</h3>
<p><em>Factor-analytic</em> or <em>reduced-rank</em> models are a more flexible approach to simplifying complex covariance functions, by doing something analogous to computing a principal components analysis on the covariance matrix and keeping a subset of the terms. In <code>glmmTMB</code> you can do this with the <code>rr()</code> covariance structure; see the relevant section of the <a href="">covariance structure vignette</a>, or <a href="https://www.math.mcmaster.ca/bolker/misc/mcgillycuddy2024.pdf">this draft</a> by McGillycuddy et al.&nbsp;in press in <em>J. Stat. Software</em>.</p>
</section>
</section>
<section id="parameter-constraint-strategies" class="level2">
<h2 class="anchored" data-anchor-id="parameter-constraint-strategies">parameter constraint strategies</h2>
<p>Instead of changing the covariance model to reduce its dimensionality, you can add a Bayesian prior (or a regularization term, if you’re not Bayesian) to make the model better behaved and/or keep it from being singular.</p>
<ul>
<li>If you want to apply a minimally informative prior that will prevent singularity, <span class="citation" data-cites="chung_nondegenerate_2013">Chung et al. (<a href="#ref-chung_nondegenerate_2013" role="doc-biblioref">2013</a>)</span> show that an improper Gamma(shape=2, rate=0) is the weakest Gamma prior for the standard deviation that will prevent a posterior mode at zero. (The mode will be “approximately one standard error away from zero when the maximum likelihood estimate is at zero”.) In practice this might be implemented using a very small rate parameter or very large shape parameter. A Wishart prior with <span class="math inline">\(\nu = 1 + d\)</span> and infinite scale might (?) have similar properties for vector-valued random effects/covariance matrices larger than 1×1. The <code>blme</code> package implements this approach (although with a default shape of 2.5 rather than 2); it can also be implemented in <code>glmmTMB</code> (see the <a href="https://cran.r-universe.dev/glmmTMB/doc/priors.html">priors vignette</a>), and of course in any of the full-Bayesian packages (<code>brms</code>, <code>rstanarm</code>, <code>MCMCglmm</code>, etc.)</li>
<li>If you’re a real Bayesian or are otherwise comfortable with stronger priors, you can choose from a variety of other priors (e.g.&nbsp;half-Normal or half-<span class="math inline">\(t\)</span> or Gamma or log-Normal priors for standard deviations, Wishart or inverse-Wishart distributions for full covariance matrices, <a href="https://en.wikipedia.org/wiki/Lewandowski-Kurowicka-Joe_distribution">LKJ priors</a> for correlations) to help out your model. (LKJ priors are a nice generalization of the diagonal covariance structures above, as an LKJ prior with <span class="math inline">\(\eta&gt;1\)</span> pushes the correlation matrix to be closer to diagonal without constraining it to be exactly diagonal …)</li>
<li>a real Bayesian would also say you should <strong>not</strong> choose priors just to make your model behave better (e.g.&nbsp;eliminate divergences in a Hamiltonian Monte Carlo run). Instead, you should use prior predictive simulations to tune the priors to limit the random-effects structures to those that produce reasonable output (and then cross your fingers that this also resolves your computational problems).</li>
</ul>
</section>
<section id="multiple-re-terms" class="level2">
<h2 class="anchored" data-anchor-id="multiple-re-terms">multiple RE terms</h2>
<p>Given all these options, any combination of which might apply to different RE terms in a model with more than one random effect, how should one choose among them?</p>
<ul>
<li>if a model seemed to be sampling or converging to an optimum reasonably well but the fit was singular (i.e.&nbsp;on the boundary of the space of allowed covariance estimates), and the results were sufficiently robust that you could get estimates and standard errors/CIs for all of the values of interest), you might choose to proceed with the singular model. Singular fits are theoretically valid; they just make a lot of downstream procedures, such as those based on calculating curvature of the log-likelihood surface, harder. It might also be reasonable to suppose that numerical procedures could be less reliable in this case.</li>
<li><span class="citation" data-cites="barr_random_2013">Barr et al. (<a href="#ref-barr_random_2013" role="doc-biblioref">2013</a>)</span> suggest “keep[ing] it maximal”, i.e.&nbsp;reducing the model only where necessary to deal convergence issues (they don’t actually mention singular fits, nor say much about the <a href="https://lme4.r-universe.dev/lme4/doc/manual.html#convergence">issues with convergence checks in lme4</a>: &gt; In cases of nonconvergence, simplification of the random effects structure proceeded as follows. For between-items designs, the by-subjects random slope was dropped. For within-items designs, statistics from the partially converged model were inspected, and the slope associated with smaller variance was dropped It doesn’t seem that they considered models with multiple random effects terms (where one wouldn’t necessarily know which term to try simplifying first …)</li>
<li><span class="citation" data-cites="matuschek_balancing_2017">Matuschek et al. (<a href="#ref-matuschek_balancing_2017" role="doc-biblioref">2017</a>)</span> prefer a model selection approach; they lay out a stepwise approach based on likelihood ratio tests with a relaxed threshold (<span class="math inline">\(\alpha = 0.2\)</span>) for retaining terms. Based on a model with two random-slopes terms, they suggest a sequence<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<ol type="1">
<li>full model</li>
<li>independent slopes and intercepts for both terms [<span class="math inline">\(\rho = 0\)</span>]</li>
<li>drop the random slope for one term [item-specific random slopes]</li>
<li>drop the random slope for the other term [subject-specific random slopes]</li>
<li>drop both random slopes They also consider AIC-based selection.</li>
</ol>
<ul>
<li><span class="citation" data-cites="moritzrole2023a">Moritz, Batllori, and Bolker (<a href="#ref-moritzrole2023a" role="doc-biblioref">2023</a>)</span> used a more complex model than either of the references above: the among-group variation of an intercept and four numeric predictors (i.e., a 5×5 covariance matrix), applied at three different grouping levels. They consider the possibilities of (1) a full (unconstrained) covariance matrix, (2) a diagonal/independent covariance, or (3) an intercept-only random effect, for each grouping variable, i.e.&nbsp;a total of <span class="math inline">\(3^3 = 81\)</span> possible models. They fitted all 81 models and chose the model with the best AIC among only the models with non-singular fits</li>
<li><span class="citation" data-cites="singmannIntroduction2019">Singmann and Kellen (<a href="#ref-singmannIntroduction2019" role="doc-biblioref">2019</a>)</span> doesn’t present any methods suggested above, but the section on “Specifying the Random Effects Structure” has a clear description</li>
<li>several R packages have implemented model selection machinery for the random effects (most of the options, e.g.&nbsp;<code>MuMIn</code>, <code>glmulti</code>, <code>glmmLasso</code>, do model selection only on the fixed effects component)
<ul>
<li>The <a href="https://cran.r-project.org/package=buildmer">buildmer</a> package is probably the fanciest: it</li>
</ul>
<blockquote class="blockquote">
<p>[f]inds the largest possible regression model that will still converge for various types of regression analyses … and then optionally performs stepwise elimination similar to the forward and backward effect-selection methods in SAS, based on the change in log-likelihood or its significance, Akaike’s Information Criterion, the Bayesian Information Criterion, the explained deviance, or the F-test of the change in R². Its allowed steps appear to include both including/excluding particular terms from the RE term for a particular grouping variable, as well as including or excluding complete terms (i.e.&nbsp;adding or dropping a grouping variable)</p>
</blockquote>
<ul>
<li><code>step.lmerModLmerTest()</code> from <a href="https://CRAN.R-project.org/package=lmerTest">lmerTest</a> does backward stepwise selection (<em>among</em> random-effects terms, i.e.&nbsp;not considering simplification of individual terms as discussed above) based on likelihood ratio tests</li>
<li><code>ffRanefLMER.fnc()</code> from <a href="https://CRAN.R-project.org/package=LMERConvenienceFunctions">LMERConvenienceFunctions</a> does forward selection (the description of the <code>ran.effects</code> argument that specifies the possible random effects is complicated …)</li>
</ul></li>
</ul>
</section>
<section id="to-do" class="level2">
<h2 class="anchored" data-anchor-id="to-do">to do</h2>
<ul>
<li>provide examples of all (!?) of these approaches. In addition to the simulated example I started with (a single RE with a multi-level factor), might need to include examples with (1) multiple continuous predictors and (2) multiple RE terms in order to illustrate everything …</li>
<li>fancy ideas; RJMCMC for Bayesian models?</li>
</ul>
</section>
<section id="references" class="level2 unnumbered">


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">references</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-barr_random_2013" class="csl-entry" role="doc-biblioentry">
Barr, Dale J., Roger Levy, Christoph Scheepers, and Harry J. Tily. 2013. <span>“Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.”</span> <em>Journal of Memory and Language</em> 68 (3): 255–78. <a href="https://doi.org/10.1016/j.jml.2012.11.001">https://doi.org/10.1016/j.jml.2012.11.001</a>.
</div>
<div id="ref-bates_parsimonious_2015" class="csl-entry" role="doc-biblioentry">
Bates, Douglas, Reinhold Kliegl, Shravan Vasishth, and Harald Baayen. 2015. <span>“Parsimonious <span>Mixed</span> <span>Models</span>.”</span> <em>arXiv:1506.04967 [Stat]</em>, June. <a href="http://arxiv.org/abs/1506.04967">http://arxiv.org/abs/1506.04967</a>.
</div>
<div id="ref-bates_fitting_2015" class="csl-entry" role="doc-biblioentry">
Bates, Douglas, Martin Mächler, Benjamin M. Bolker, and Steven C. Walker. 2015. <span>“Fitting Linear Mixed-Effects Models Using <span class="nocase">lme4</span>.”</span> <em>Journal of Statistical Software</em> 67 (1): 1–48. <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-chung_nondegenerate_2013" class="csl-entry" role="doc-biblioentry">
Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and Jingchen Liu. 2013. <span>“A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models.”</span> <em>Psychometrika</em>, 1–25. <a href="https://doi.org/10.1007/s11336-013-9328-2">https://doi.org/10.1007/s11336-013-9328-2</a>.
</div>
<div id="ref-matuschek_balancing_2017" class="csl-entry" role="doc-biblioentry">
Matuschek, Hannes, Reinhold Kliegl, Shravan Vasishth, Harald Baayen, and Douglas Bates. 2017. <span>“Balancing Type <span>I</span> Error and Power in Linear Mixed Models.”</span> <em>Journal of Memory and Language</em> 94: 305–15. <a href="https://doi.org/10.1016/j.jml.2017.01.001">https://doi.org/10.1016/j.jml.2017.01.001</a>.
</div>
<div id="ref-moritzrole2023a" class="csl-entry" role="doc-biblioentry">
Moritz, Max A., Enric Batllori, and Benjamin M. Bolker. 2023. <span>“The Role of Fire in Terrestrial Vertebrate Richness Patterns.”</span> <em>Ecology Letters</em> 26 (4): 563–74. <a href="https://doi.org/10.1111/ele.14177">https://doi.org/10.1111/ele.14177</a>.
</div>
<div id="ref-singmannIntroduction2019" class="csl-entry" role="doc-biblioentry">
Singmann, Henrik, and David Kellen. 2019. <span>“An <span>Introduction</span> to <span>Mixed</span> <span>Models</span> for <span>Experimental</span> <span>Psychology</span>.”</span> In <em>New <span>Methods</span> in <span>Cognitive</span> <span>Psychology</span></em>, edited by Daniel Spieler and Eric Schumacher, 1st ed., 4–31. Routledge. <a href="https://doi.org/10.4324/9780429318405-2">https://doi.org/10.4324/9780429318405-2</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I don’t understand how we choose between models 3 and 4 in this list; they are both nested in model 2 and contain model 5, but neither is nested in the other …<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>